{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de27e552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://androidkt.com/use-saved-pytorch-model-to-predict-single-and-multiple-images/\n",
    "# https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-predict-new-samples-with-your-pytorch-model.mdS\n",
    "# https://towardsdatascience.com/optimize-pytorch-performance-for-speed-and-memory-efficiency-2022-84f453916ea6\n",
    "# https://www.kaggle.com/code/andradaolteanu/pytorch-rnns-and-lstms-explained-acc-0-99#3.-RNN-with-1-Layer-%F0%9F%93%98\n",
    "# https://www.kaggle.com/code/omershect/learning-pytorch-lstm-deep-learning-with-m5-data/comments\n",
    "# https://curiousily.com/posts/time-series-anomaly-detection-using-lstm-autoencoder-with-pytorch-in-python/\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7376709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Device is:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Available Device is: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2b69f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./robotdatacollection3/ep2.csv')\n",
    "feature_list = ['Fy']\n",
    "TIMESTEP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "530ef679",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding dimension: (5351, 1)\n",
      "Shape AFTER adding dimension: (5351, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "df_new = df[feature_list].to_numpy()\n",
    "print('Shape before adding dimension:',df_new.shape)\n",
    "df_new = np.expand_dims(df_new, axis=1)\n",
    "print('Shape AFTER adding dimension:',df_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db0fdf",
   "metadata": {},
   "source": [
    "### Try using Or's approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "433bf452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the input to \n",
    "# batch=1, timestep=values, features=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e58537ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the data in a window form, in case of timestep = 5\n",
    "# i=0: X_0=[x(0)..x(5)], y=x(6)\n",
    "\n",
    "def to_sequence(data, timesteps=1):\n",
    "    n_features=data.shape[2]\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data)-timesteps):\n",
    "        # takes a window of data of specified timesteps\n",
    "        \n",
    "        _x = data[i:(i+timesteps)]\n",
    "        _x = _x.reshape(timesteps, n_features)\n",
    "#         print(_x.shape)\n",
    "        _y = data[i+timesteps]\n",
    "        _y = _y.reshape(n_features)\n",
    "#         print(_y.shape)\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "        \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1b31dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = to_sequence(df_new, timesteps=TIMESTEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b8cc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25a773c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = df_new #np.ones((1,5351))#\n",
    "# y_train = np.ones((5351,1))# np.ones((5351,1))# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "691eb66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5301, 50, 1])\n",
      "torch.Size([5301, 1])\n"
     ]
    }
   ],
   "source": [
    "trainX = torch.Tensor(x_train)\n",
    "trainy = torch.Tensor(y_train)\n",
    "print(trainX.shape)\n",
    "print(trainy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35d18f",
   "metadata": {},
   "source": [
    "**Pytorch uses Tensors as inputs to the model, so we convert numpy to Tensor**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1214298",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "\n",
    "LSTM layers work on 3D data with the following structure `(sequence/batch, timestep, feature)`.\n",
    "\n",
    "* **input_dim**: Number of samples in the data. In our case we do not use batches but instead one sample at a time. Each sample has TIMESTEP size of data in it. \n",
    "* **hidden_dim**: Number of LSTM cells\n",
    "* **layer_dim**: Number of LSTM hidden layers\n",
    "* **output_dim**: Number of outputs = feature number (in case of regression task)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f376f3c",
   "metadata": {},
   "source": [
    "https://cnvrg.io/pytorch-lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf9bc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bidirectional LSTM: extensions that can improve performance. They train model forward and backward on the same input\n",
    "# much slower, good for NLP \n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, batch_size, sequence_length, input_size, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__() # inherit from nn.Module\n",
    "        \n",
    "        # N: sample size, each sample containts sequence of length L\n",
    "        self.batch_size = batch_size\n",
    "        # L: sequence length \n",
    "        self.sequence_length = sequence_length\n",
    "        # Hin: input size, number of features in the input X\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # hidden dims\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # building LSTM\n",
    "        # setting batch_first=True: input and output order:(N,L,Hin)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, batch_first=True)\n",
    "        #         self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # output layer (OK) \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # initialize hidden state with zeros\n",
    "        hidden_state = torch.zeros(1, self.batch_size, self.hidden_dim)\n",
    "        # initialize cell state\n",
    "        cell_state = torch.zeros(1, self.batch_size, self.hidden_dim)\n",
    "        # input order:(N,L,Hin) for batch_first = True  \n",
    "        # view() reshapes tensor without copying memory\n",
    "        x = x.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "#         print(x.shape)\n",
    "\n",
    "        # output, (h_n, c_n): \n",
    "        # we need to detach tensor from current graph\n",
    "        # if we do not, we will backpop all the way to the start even after going through another batch\n",
    "        out, (last_hidden_state, last_cell_state) = self.lstm(x, (hidden_state, cell_state))\n",
    "\n",
    "#         out, (hn, cn) = self.lstm(X, (h_0, c_0))\n",
    "#         print('output shape', out.shape)\n",
    "        \n",
    "        # index hidden state of last time step\n",
    "        # out.size() -> 100,28,100\n",
    "        # out[:,-1,:] -> 100, 100-> just want last time step hidden states\n",
    "        out = self.fc(out[:,-1,:])\n",
    "#         print('reshape',out.shape)\n",
    "        # out.size() --> 100,10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312b6e6",
   "metadata": {},
   "source": [
    "* `batch_size`: N-different measurements, each contains sequence of length L\n",
    "* `sequence_length`: L: length of each time series sequence\n",
    "* `input_size`: Hin: number of features\n",
    "* `hidden_dim`: number of units in LSTM layer\n",
    "* `output_dim`: output size/ how many predictions at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6886988c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5301, 50, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8aea475",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = trainX.shape[0]\n",
    "sl = trainX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38c53414",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMModel(batch_size=bs,\n",
    "                       sequence_length=sl, \n",
    "                       input_size=1, \n",
    "                       hidden_dim=15, \n",
    "                       output_dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input_dim = 1#  timestep\n",
    "# hidden_dim = 5 # LSTM layer 5 units\n",
    "# layer_dim = 1 # one LSTM layer\n",
    "# output_dim = 1 # we outout one prediction at a time\n",
    "\n",
    "# lstm_model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "093e8067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(1, 15, batch_first=True)\n",
       "  (fc): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ebf7d8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.744158148765564\n",
      "Epoch 10, Loss 0.6845821142196655\n",
      "Epoch 20, Loss 0.6352720260620117\n",
      "Epoch 30, Loss 0.5895519852638245\n",
      "Epoch 40, Loss 0.5426255464553833\n"
     ]
    }
   ],
   "source": [
    "# regression, calculates the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "# updates the weights and biases to reduce loss\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training LSTM for each epoch we\n",
    "for epoch in range(50):\n",
    "    \n",
    "    # enable train mode\n",
    "    lstm_model.train(True)\n",
    "    \n",
    "    # clear gradients with respect to params, always before backprop\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(True):\n",
    "        \n",
    "        # forward pass to get outputs/ make predictions for that batch\n",
    "        output = lstm_model(trainX)\n",
    "\n",
    "        # calculate loss and its gradients\n",
    "        loss = criterion(output, trainy)\n",
    "        # getting gradients w.r.t. params\n",
    "        loss.backward()\n",
    "\n",
    "        #updating params/ weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a65ae105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5301, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d71e2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5301, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed4c5066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09427380561828613\n",
      "0.07773137092590332\n",
      "0.07767796516418457\n",
      "0.07771062850952148\n",
      "0.07795238494873047\n",
      "0.07773184776306152\n",
      "0.0729987621307373\n",
      "0.05622577667236328\n",
      "0.05527138710021973\n",
      "0.05552220344543457\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "\n",
    "times_dnn = []\n",
    "lstm_model.eval()\n",
    "torch.no_grad()\n",
    "\n",
    "while t < 10:\n",
    "    t_start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = lstm_model(trainX)\n",
    "        \n",
    "    dt = time.time()-t_start\n",
    "    print(dt)\n",
    "    \n",
    "    times_dnn.append(dt)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dae278f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5301, 50, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90e2ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(1,2)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b52f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMModel(batch_size=bs,\n",
    "                       sequence_length=sl, \n",
    "                       input_size=1, \n",
    "                       hidden_dim=15, \n",
    "                       output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94f1339b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5301, 50, 1]' is invalid for input of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlstm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         cell_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# input order:(N,L,Hin) for batch_first = True  \u001b[39;00m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;66;03m# view() reshapes tensor without copying memory\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#         print(x.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# output, (h_n, c_n): \u001b[39;00m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# we need to detach tensor from current graph\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# if we do not, we will backpop all the way to the start even after going through another batch\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         out, (last_hidden_state, last_cell_state) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, (hidden_state, cell_state))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[5301, 50, 1]' is invalid for input of size 2"
     ]
    }
   ],
   "source": [
    "lstm_model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc0240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
